import { fp8 } from '@/data/fp8'

# FP8

The 8-bit floating point format is a compact numerical representation of real numbers, where each number is represented by a single byte. It is commonly used in machine learning applications where memory usage and bandwidth capabilities are especially important.

## Anatomy of an FP8

Unlike [FP32](/numbers/quantize/fp32), FP8 is not standardized - while every FP8 format uses 1 bit for the sign, the choice on how the remaining 7 bits should be divided between mantissa and exponent is dependent on the specific FP8 format being used.

Since an FP8 can represent 256 possible values, it is easy to visualize their numeric range and distribution with a table.

<FP8Table fp={ fp8.e4m3 }/>

<FP8Table fp={ fp8.e4m3fnuz }/>

<FP8Table fp={ fp8.e5m2 }/>

<FP8Table fp={ fp8.e5m2fnuz }/>